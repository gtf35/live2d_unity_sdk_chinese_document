# 「Live2D Unity 文档翻译」实现口型同步

本文翻译自：https://docs.live2d.com/cubism-sdk-tutorials/lipsync/

译者注：注意！这并不是一篇严谨的翻译，本人并不是翻译行业从业者，也根本不会日文。官网的中文翻译会连带代码一起翻译，而且还不如机翻日文，官网的英语翻译版本有的语法很奇怪，看起来也是机翻。本文主要来自日文机翻，然后再结合实际开发经验调整到通顺，修改不该翻译的东西并润色。

[最后更新日期: 2020/01/30] 译者注：这是这个日文原文的更新日期	





在这里，我们将说明如何使模型的口型和  `AudioSource` 的音量同步。

[ [导入 SDK-放置模型 ](https://docs.live2d.com/cubism-sdk-tutorials/getting-started/)] 假设模型已经放置到项目中。

要从 AudioSource 获取音量并处理，请准备 Unity 能够处理的音频文件。

## 摘要

`Cubism SDK` 中使用一个名为 `MouthMovement` 的组件来实现口型同步。

要在`Cubism`模型上设置`MouthMovement`，请需要以下 3 步：

1. 附加一个管理口型同步的组件
2. 设置进行唇形同步的参数
3. 设置用于自动处理唇形参数值的组件

## 附加一个管理口型同步的组件

将名为`CubismMouthController`的组件附加到模型的 `GameObject` 上，用于管理口形同步。

![img](https://docs.live2d.com/wp-content/uploads/2017/08/lipsync01.png)

![img](https://docs.live2d.com/wp-content/uploads/2017/08/lipsync02.png)

`CubismMouthController` 有两个设置项

- Blend Mode : 指定如何计算当前张口的大小。

  译者注：就是如何计算嘴巴张开多大。如果模型里做了张嘴的设置，Unity 里再去设置就会冲突，这里主要是为了解决那个冲突

  - Mutiply : 将当前值乘以 "Mouth Opening" 值。

  - Additive : 将当前值乘以 "Mouth Opening" 值

  - Override : 用 "Mouth Opening" 值覆盖当前值。

    译者注：要是模型里面有的动作里嘴是会动的，。但是这样就是有了两个能控制嘴动的方式，于是就有了「Blend Mode」。其中：「当前值」就是模型自带的动画里的值，「Mouth Opening」就是 `CubismMouthController` 的值。最后结果如何混合就是「Blend Mode」决定的了。

- Mouth Opening：

  嘴巴张开和闭合的幅度。1 视为嘴完全张开，0 视为嘴完全闭合。当从外部操纵该值时，将会自动应用修改（译者注：嘴就会自己跟着变化）。

这次，将 [Blend Mode/混合模式] 设置为 [Override/覆盖]。

![img](https://docs.live2d.com/wp-content/uploads/2017/08/lipsync03.png)

## 设置进行唇形同步的参数

管理模型参数的 `GameObject` 放置在 `[模型]/Parameters/` 下。

此外，他们的名称是参数的 ID。

他们都可以通过 `CubismModel.Parameters()` 获得。

将一个名为 `CubismMouthParameter` 的组件附加到表示眨眼的参数 ID 所在组件上。

译者注：就是在代表嘴巴的 GameObject 上面附加个 `CubismMouthParameter` ，当然你要附在例如呆毛或者某些奇怪的地方也没人管你🤔，在运行的时候 `CubismMouthController`  就会自动调整这个值来实现张嘴和闭嘴。

![img](https://docs.live2d.com/wp-content/uploads/2017/08/lipsync04.png)

![img](https://docs.live2d.com/wp-content/uploads/2017/08/lipsync05.png)

通过以上设置，您将可以控制模型张开或者闭上嘴巴了

但是，只是这样还不够，还不能进行口形同步。

为了自动进行唇形同步，还需要设置一个组件来控制 `CubismMouthController` 的 `Mouth Opening` 值。

## 设置用于自动处理唇形参数值的组件

将口型同步输入组件附加到用于显示模型的 GameObject上。

MouthMovement 包含一些组件，这些组件可以根据 AudioSource 的音量和正弦波来操纵嘴张开/闭合的具体大小。

这次，我们将附加一个名为 `CubismAudioMouthInput` 的组件，以便于我们从 `AudioSource`  获取数值。

![img](https://docs.live2d.com/wp-content/uploads/2017/08/lipsync_audio01.png)

![img](https://docs.live2d.com/wp-content/uploads/2017/08/lipsync_audio02.png)

`CubismAudioMouthInput` 具有以下四个设置项目。

- Audio Input（音频输入） : 设置用于输入的 AudioSource。这里 `AudioSource` 中 `AudioClip` 的音量。
- Sampling Quality（采样质量） : 设置要采样的精度。以下设置的顺序往下，精度越高，但是计算量也越大。
  - High			（高）
  - Very High    （较高）
  - Maximum    （最大）
- Gain（增益） : 设置处理采样量的次数。 1 是相同。
- Smoothing（平滑） : 设置切换张嘴/闭嘴之间的平滑程度。该值越高，将越平滑，但也会增加计算负荷。

这次，设置如下。其中 `Audio Input` 需要设置一个附加了 `AudioSource` 的 `GameObject` 。

\- Sampling Quality：High
\- Gain：1
\- Smoothing：5



最后，为了获得音量，请将 `AudioSource` 附加到任意一个 `GameObject` 并将其设置为上述 `CubismAudioMouthInput` 的 `Audio Input` 中。（译者注：没错他又说了一遍）

![img](https://docs.live2d.com/wp-content/uploads/2017/08/lipsync_audio03.png)

![img](https://docs.live2d.com/wp-content/uploads/2017/08/lipsync_audio05.png)

这样就实现了唇形同步。

如果当前状态下运行场景，在播放在 `AudioSource` 中设置的音频文件的同时，模型将根据音量同步口型。

![img](https://docs.live2d.com/wp-content/uploads/2017/08/lipsync_audio.gif)